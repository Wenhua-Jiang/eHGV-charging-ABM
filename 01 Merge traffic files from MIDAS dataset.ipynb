{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88ebf092",
   "metadata": {},
   "source": [
    "#### Analyze the MIDAS dataset to merge traffic on M20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "997923aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import os\n",
    "import multiprocess\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4f7a7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to process each file and filter data\n",
    "def process_file(file_path):\n",
    "    try:\n",
    "        # Read the CSV file\n",
    "        data = pd.read_csv(file_path)\n",
    "        \n",
    "        # Filter rows containing \"M20\" in \"site_ID\"\n",
    "        data_m20 = data[data[\"site_ID\"].str.contains(\"M20\")]\n",
    "        \n",
    "        return data_m20\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {file_path} is missing.\")\n",
    "        return pd.DataFrame()  # Return empty DataFrame in case of error\n",
    "\n",
    "# Function to generate the file paths\n",
    "def generate_file_paths():\n",
    "    file_paths = [f'/Users/wjiang/OneDrive - The Alan Turing Institute/Full_History/2_01_combined_15min_site_level_kent000000000{i:03}.csv' for i in range(700)]\n",
    "    return file_paths\n",
    "\n",
    "# Function to divide the file list into chunks\n",
    "def chunk_file_list(file_list, num_chunks):\n",
    "    avg_chunk_size = len(file_list) // num_chunks\n",
    "    return [file_list[i:i + avg_chunk_size] for i in range(0, len(file_list), avg_chunk_size)]\n",
    "\n",
    "# Main function that orchestrates the multiprocessing\n",
    "def main():\n",
    "    # Generate file paths\n",
    "    file_list = generate_file_paths()\n",
    "\n",
    "    # Define number of worker processes\n",
    "    num_workers = 8  # You can adjust based on your machine's CPU cores\n",
    "\n",
    "    # Split the file list into chunks\n",
    "    file_chunks = chunk_file_list(file_list, num_workers)\n",
    "\n",
    "    # Create a Pool of workers to process the file chunks\n",
    "    with multiprocess.Pool(processes=num_workers) as pool:\n",
    "        # Use tqdm to track progress of the iterable\n",
    "        result = list(\n",
    "            tqdm(\n",
    "                pool.imap(process_file, file_list),\n",
    "                total=len(file_list),\n",
    "                desc=\"Processing files\"\n",
    "            )\n",
    "        )\n",
    "    # Concatenate all filtered data into a single DataFrame\n",
    "    df_M20 = pd.concat(result, ignore_index=True)\n",
    "\n",
    "    # Save the merged DataFrame to a CSV file\n",
    "    df_M20.to_csv('combined_M20.csv', index=False)\n",
    "\n",
    "    print(\"M20 data merged and saved to 'merged_M20.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8636d973",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  33%|███████▍               | 228/700 [00:09<00:19, 24.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /Users/wjiang/OneDrive - The Alan Turing Institute/Full_History/2_01_combined_15min_site_level_kent000000000235.csv is missing.\n",
      "File /Users/wjiang/OneDrive - The Alan Turing Institute/Full_History/2_01_combined_15min_site_level_kent000000000238.csv is missing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  52%|███████████▉           | 362/700 [00:14<00:13, 25.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /Users/wjiang/OneDrive - The Alan Turing Institute/Full_History/2_01_combined_15min_site_level_kent000000000370.csv is missing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  69%|███████████████▊       | 481/700 [00:18<00:07, 28.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /Users/wjiang/OneDrive - The Alan Turing Institute/Full_History/2_01_combined_15min_site_level_kent000000000488.csv is missing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing files:  69%|███████████████▉       | 484/700 [00:18<00:07, 27.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /Users/wjiang/OneDrive - The Alan Turing Institute/Full_History/2_01_combined_15min_site_level_kent000000000494.csv is missing.\n",
      "File /Users/wjiang/OneDrive - The Alan Turing Institute/Full_History/2_01_combined_15min_site_level_kent000000000495.csv is missing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|███████████████████████| 700/700 [00:27<00:00, 25.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M20 data merged and saved to 'merged_M20.csv'.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1505b030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bc98ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
